---
title: "Main Code"
author: "Margaret Perry"
date: "November 18, 2018"
output: pdf_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
library(readr)
library(igraph)
library(sna)
library(sand)
library(blockmodels)
library(sna)
library(dplyr)
```

##import data 

```{r}
library(sna)
library(network)
data1<-read.csv("CSV/60_PERIOD1_ATTT.csv")
data2<-read.csv("CSV/60_PERIOD2_ATT.csv")
data3<-read.csv("CSV/60_PERIOD3_ATT.csv")
edges1<-read.csv("CSV/60_PERIOD1_NET.csv", header=TRUE)
edges2<-read.csv("CSV/60_PERIOD2_NET.csv", header=TRUE)
edges3<-read.csv("CSV/60_PERIOD3_NET.csv", header=TRUE)
```

## creating adjency matrix for the three dataset 

```{r}
# change character form into numarical form:
adj.matrix.1<-as.matrix(edges1)[,-1] # make sure as many columns as rows
class(adj.matrix.1)<-"numeric"

adj.matrix.2<-as.matrix(edges2)[,-1] # make sure as many columns as rows
class(adj.matrix.2)<-"numeric"

adj.matrix.3<-as.matrix(edges3)[,-1] # make sure as many columns as rows
class(adj.matrix.3)<-"numeric"

```

## examing missing data 

Here we can compare the number of missing data with the number of total data
```{r}
nrow(data1[data1$Marital.Status!=99999,]) # see valid data with marrital status not missing for data 1
nrow(data2[data2$Marital.Status!=99999,]) # same thing for data 2 
nrow(data3[data3$Marital.Status!=99999,]) # for data 3

nrow(data1)
nrow(data2)
nrow(data3)
```

##Visualizing 

```{r}
gplot(adj.matrix.1,main="Period 1", vertex.col="Blue")
gplot(adj.matrix.2,main="Period 2", vertex.col="Purple")
gplot(adj.matrix.3,main="Period 3", vertex.col = "Orange")

```


## Blockmodel 
```{r}
my_model<-BM_bernoulli(
"SBM",
adj.matrix.1,
verbosity=6,
autosave='',
plotting=character(0),
exploration_factor=1.5,
explore_min=2,
explore_max=7,
ncores=detectCores())

my_model$estimate()

which.max(my_model$ICL)

num.clusters<-4 #use number from which.max command above
my_model$memberships[[num.clusters]]$Z#gives probability of being in each group
test1=my_model$memberships[[num.clusters]]$Z>0.6
test1
#typeof(test1)

# Add group variable to dataset "daat1", named "data1.1"
test2=data.frame(test1)
data3.1<-data1 %>%
  mutate(group = "NA")
test2.1<-test2 %>%
  mutate(group="NA")

test2.2<-test2.1 %>%
  mutate(group=ifelse(X1=="TRUE", 1,ifelse(X2=="TRUE",2, ifelse(X3=="TRUE",3,ifelse(X4=="TRUE",4,0)))))
data1.1=cbind(data1, test2.2[5])
```
We see that there are likely to have four to five groups within the whole dataset. Now we are going to calculate the likelookd for each individual of being in those groups based on some of their specific background information. 

## Multinomial Logistic Regression 
```{r}
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
data1
test <- multinom( ~ Gender + Marital.Status, data = data1)

```
# Discussion
We can then run the regression 
